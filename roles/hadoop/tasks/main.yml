---
# file: roles/cdh-common/tasks/main.yml

- name: Add CDH4 apt repository (Ubuntu precise)
  apt_repository: repo='deb [arch=amd64] http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh precise-cdh4 contrib'
  tags: [hadoop, hive]


- name: Add CDH4 repository key (Ubuntu precise)
  apt_key: url=http://archive.cloudera.com/cdh4/ubuntu/precise/amd64/cdh/archive.key
  tags: [hadoop, hive]

- name: Update apt repo
  apt: update_cache=yes
  tags: [hadoop, hive]

- name: Install JobTracker
  apt: pkg=hadoop-0.20-mapreduce-jobtracker
  tags: [hadoop, hive]

- name: Install NameNode
  apt: pkg=hadoop-hdfs-namenode
  tags: [hadoop, hive]

# - name: Set the hostname of each system to a unique name
# - name: Make sure the /etc/hosts file on each system contains the IP addresses and fully-qualified domain names (FQDN) of all the members of the cluster

- name: Configure HDFS (1/3)
  template: >
    src=core-site.xml.j2 
    dest=/etc/hadoop/conf/core-site.xml
    owner=root
    group=hadoop
    mode=0644
  tags: [hadoop, hive]

- name: Configure HDFS (2/3)
  template: >
    src=hdfs-site.xml.j2 
    dest=/etc/hadoop/conf/hdfs-site.xml
    owner=root
    group=hadoop
    mode=0644
  tags: [hadoop, hive]

- name: Ensure NameNode data directory
  file: >
    path=/data/dfs/nn 
    recurse=yes 
    owner=hdfs 
    group=hdfs 
    mode=0700
    state=directory
  tags: [hadoop, hive]

- name: ensure JAVA_HOME
  lineinfile: dest=/etc/environment regexp=^JAVA_HOME= line=JAVA_HOME=/usr/lib/jvm/java-6-oracle/
  tags: [hadoop, hive]

- name: format HDFS, if necessary
  shell: >
    hadoop namenode -format 
    creates=/data/dfs/nn/current
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]

- name: Ensure HDFS is running
  service: name=hadoop-hdfs-namenode state=started
  tags: [hadoop, hive, foo]  
  
- name: Create HDFS /tmp, if necessary
  shell: >
    hadoop fs -mkdir /tmp
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive, foo]  

- name: Configure HDFS (3/3)
  template: >
    src=mapred-site.xml.j2 
    dest=/etc/hadoop/conf/mapred-site.xml
    owner=root
    group=hadoop
    mode=0644
  tags: [hadoop, hive]
  
  - name: Create local storage directories for use by MapReduce (1/2)
  shell: >
    mkdir -p /data/mapred/local
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Create local storage directories for use by MapReduce (2/2)
  shell: >
    chown -R mapred:hadoop /data/mapred/local
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Deploy Custom Configuration to Entire Cluster (1/2)
  shell: >
    alternatives --verbose --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.my_cluster 50
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Deploy Custom Configuration to Entire Cluster (2/2)
  shell: >
    alternatives --set hadoop-conf /etc/hadoop/conf.my_cluster
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Start HDFS on Every Node in the Cluster (1/2)
  shell: cd /etc/init.d ; ls hadoop-hdfs-*
  register: command_result
  tags: [hadoop, hive]

  - name: Start HDFS on Every Node in the Cluster (2/2)
  shell: service {{ item }}
  with_items: command_result.stdout_lines
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Create the HDFS /tmp Directory with the right permissions (1/2)
  shell: >
    hadoop fs -mkdir /tmp
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name: Create the HDFS /tmp Directory with the right permissions (2/2)
  shell: >
    hadoop fs -chmod -R 1777 /tmp
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name: Create and Configure the mapred.system.dir Directory in HDFS (1/2)
  shell: >
    hdfs hadoop fs -mkdir /tmp/mapred/system
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name: Create and Configure the mapred.system.dir Directory in HDFS (2/2)
  shell: >
    hadoop fs -chown mapred:hadoop /tmp/mapred/system
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name:  start the TaskTracker service
  shell: >
    service hadoop-0.20-mapreduce-tasktracker start
  sudo: yes
  tags: [hadoop, hive]
  
  - name:  start the JobTracker  service
  shell: >
    service hadoop-0.20-mapreduce-jobtracker start
  sudo: yes
  tags: [hadoop, hive]
  
  - name: Create a Home Directory for each MapReduce User (1/2)
  shell: >
    hadoop fs -mkdir /user/$USER
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name: Create a Home Directory for each MapReduce User (2/2)
  shell: >
    hadoop fs -chown $USER /user/$USER
  sudo: yes
  sudo_user: hdfs
  tags: [hadoop, hive]
  
  - name:  Configuring init to Start Core Hadoop System Services (On the NameNode)
  shell: >
    update-rc.d hadoop-hdfs-namenode defaults
  sudo: yes
  tags: [hadoop, hive]
  
  - name:  Configuring init to Start Core Hadoop System Services (On the JobTracker)
  shell: >
    update-rc.d hadoop-0.20-mapreduce-jobtracker defaults
  sudo: yes
  tags: [hadoop, hive]
  
  - name:  Configuring init to Start Core Hadoop System Services (On the TaskTracker)
  shell: >
    update-rc.d hadoop-0.20-mapreduce-tasktracker defaults
  sudo: yes
  tags: [hadoop, hive]
  
- name: Install Hive
  apt: pkg=hive hive-metastore update_cache=yes
  tags: [hadoop, hive]
 
  - name: Install MySQL
  apt: pkg=mysql
  tags: [hadoop, hive]
  
  - name:  start MySQL
  shell: >
    service mysql start
  sudo: yes
  tags: [hadoop, hive]
  
  - name: install MySQL connector (1/2)
  apt: pkg=libmysql-java
  tags: [hadoop, hive]
  
  - name: install MySQL connector (2/2)
  shell: >
    ln -s /usr/share/java/libmysql-java.jar /usr/lib/hive/lib/libmysql-java.jar
  sudo: yes
  tags: [hadoop, hive]
  
  - name: set the MySQL root password
  shell: >
    spawn /usr/bin/mysql_secure_installation
	
	expect "Enter current password for root (enter for none):"
	send "\r"
		
	expect "Set root password?"
	send "y\r"

	expect "New password:"
	send "root\r"

	expect "Re-enter new password:"
	send "root\r"

	expect "Remove anonymous users?"
	send "y\r"

	expect "Disallow root login remotely?"
	send "n\r"

	expect "Remove test database and access to it?"
	send "y\r"

	expect "Reload privilege tables now?"
	send "y\r"
  sudo: yes
  tags: [hadoop, hive]
  
  - name: ensure the MySQL server starts at boot
  shell: >
    chkconfig mysql on
  sudo: yes
  tags: [hadoop, hive]
  
  - name: create database 'metastore' and init schema
  mysql_db: name=metastore state=import target=/usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql login_user=root login_password=root
  # shell: mysql -uroot -proot metastore < /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql
  tags: [hadoop, hive]
  
  - name: add and grant MySQL user 'hive'
  mysql_user: name=hive password=hive priv=metastore.*:ALL state=present host=localhost
  tags: [hadoop, hive]
  
  # continue with http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Installation-Guide/cdh4ig_hive_metastore_configure.html?scroll=topic_18_4_1_unique_1__title_508_unique_1